{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a906b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arthurxiao/opt/anaconda3/envs/foodApp/lib/python3.11/site-packages/pinecone/index.py:4: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pinecone\n",
    "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
    "from langchain.schema.document import Document\n",
    "import more_itertools\n",
    "from datetime import datetime\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Pinecone\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from tqdm.auto import tqdm\n",
    "from uuid import uuid4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3328a63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "# model_name = 'text-embedding-ada-002'\n",
    "# embeddings = OpenAIEmbeddings(\n",
    "#                 document_model_name=model_name,\n",
    "#                 query_model_name=model_name,\n",
    "#                 openai_api_key=os.getenv('OPENAI_API_KEY')\n",
    "#             )\n",
    "\n",
    "# Initialize e5-large-v2 embeddings model\n",
    "model_kwargs = {'device': 'cpu'}\n",
    "encode_kwargs = {'normalize_embeddings': False}\n",
    "\n",
    "embeddings_model = HuggingFaceEmbeddings(model_name=\"intfloat/e5-large-v2\",\n",
    "                                     model_kwargs=model_kwargs,\n",
    "                                     encode_kwargs=encode_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05c143b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final total of 268 documents from 254 reviews.\n",
      "Average word of count of each document: 159.11194029850745\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('infatuation_reviews_v2.pkl', 'rb') as file:\n",
    "    resto_reviews = pickle.load(file)\n",
    "    \n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=2500,\n",
    "                                     chunk_overlap=800,\n",
    "                                     length_function=len)\n",
    "final_docs = []\n",
    "total_word_cnt = 0\n",
    "for resto in resto_reviews:\n",
    "    cleaned_review = resto_reviews[resto]['review'].replace('&apos;', \"'\").replace(\"&amp;\", \"&\").replace('&quot;', '\"').replace(\"&quot\", '\"')\n",
    "    # Split review text into chunks\n",
    "    split_review_docs = text_splitter.create_documents([cleaned_review])\n",
    "    # Loop through each chunk and assign metadata\n",
    "    for doc in split_review_docs:\n",
    "        doc.metadata['resto_name'] = resto.replace(\"&amp;\", \"&\").replace('&apos;', \"'\")\n",
    "#         doc.metadata['food_rundown'] = resto_reviews[resto]['food_rundown'].replace(\"&amp;\", \"&\").replace('&apos;', \"'\")\n",
    "        doc.metadata['cuisine'] = resto_reviews[resto]['cuisine']\n",
    "        doc.metadata['perfect_for_tags'] = resto_reviews[resto]['perfect_for_tags'].replace(\"&amp;\", \"&\").replace('&apos;', \"'\")\n",
    "        doc.metadata['price_range'] = resto_reviews[resto]['price_range']\n",
    "        doc.metadata['review_date'] = resto_reviews[resto]['review_date'].split('T')[0]\n",
    "        # Add document to final list of documents\n",
    "        final_docs.append(doc)\n",
    "        total_word_cnt += len(doc.page_content.split())\n",
    "\n",
    "print(f'Final total of {len(final_docs)} documents from {len(resto_reviews)} reviews.')\n",
    "print(f'Average word of count of each document: {total_word_cnt/len(final_docs)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "852fc1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Pinecone\n",
    "pinecone.init(\n",
    "    api_key=os.getenv('PINECONE_API_KEY'),\n",
    "    environment=os.getenv('PINECONE_ENVIRONMENT'),\n",
    ")\n",
    "\n",
    "# Get chompt pinecome index name\n",
    "index_name = os.getenv('PINECONE_INDEX_NAME')\n",
    "\n",
    "# pinecone.create_index(\n",
    "#     name=index_name,\n",
    "#     metric='cosine',\n",
    "#     dimension=1024\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7cce787d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original reviews list (268 reviews) split into smaller lists (9 reviews)\n",
      "Stored sub list 1 in Pinecone!\n",
      "Stored sub list 2 in Pinecone!\n",
      "Stored sub list 3 in Pinecone!\n",
      "Stored sub list 4 in Pinecone!\n",
      "Stored sub list 5 in Pinecone!\n",
      "Stored sub list 6 in Pinecone!\n",
      "Stored sub list 7 in Pinecone!\n",
      "Stored sub list 8 in Pinecone!\n",
      "Stored sub list 9 in Pinecone!\n",
      "Finished storing Infatuation reviews in Pinecone... Broncos Country! Let's Ride!!\n"
     ]
    }
   ],
   "source": [
    "# Split docs into batches\n",
    "sub_docs = list(more_itertools.batched(final_docs, 30))\n",
    "print(f\"Original reviews list ({len(final_docs)} reviews) split into smaller lists ({len(sub_docs)} lists)\")\n",
    "print(f\"Start time: {datetime.now()}\")\n",
    "for count, doc_list in enumerate(sub_docs):\n",
    "    vector_store = Pinecone.from_documents(list(doc_list),\n",
    "                                        embedding=embeddings,\n",
    "                                        index_name=index_name)\n",
    "    print(f\"Stored sub list {count+1} in Pinecone!\")\n",
    "print(\"Finished storing Infatuation reviews in Pinecone... Broncos Country! Let's Ride!!\")\n",
    "print(f\"End time: {datetime.now()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a53237c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1024,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {},\n",
       " 'total_vector_count': 0}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pinecone.delete_index(index_name)\n",
    "\n",
    "pinecone.create_index(\n",
    "    name=index_name,\n",
    "    metric='cosine',\n",
    "    dimension=1024\n",
    ")\n",
    "\n",
    "index = pinecone.Index(index_name)\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e0ff9a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The fruit is: _fruit. Tester: apple', 'The fruit is: _fruit. Tester: banana', 'The fruit is: _fruit. Tester: orange']\n"
     ]
    }
   ],
   "source": [
    "my_list = ['apple', 'banana', 'orange']\n",
    "suffix_to_add = '_fruit'\n",
    "\n",
    "# Loop through the list and add the suffix to each element in place\n",
    "my_list = [f'The fruit is: {suffix_to_add}. Tester: ' + element for element in my_list]\n",
    "\n",
    "print(my_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3bbd8d29",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start time: 2023-12-08 20:05:38.309933\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17a52c30052e40e88d110c14e6019764",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/255 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunking and preparing review #0...\n",
      "Chunking and preparing review #1...\n",
      "Chunking and preparing review #2...\n",
      "Chunking and preparing review #3...\n",
      "Chunking and preparing review #4...\n",
      "Chunking and preparing review #5...\n",
      "Chunking and preparing review #6...\n",
      "Chunking and preparing review #7...\n",
      "Chunking and preparing review #8...\n",
      "Chunking and preparing review #9...\n",
      "Chunking and preparing review #10...\n",
      "Chunking and preparing review #11...\n",
      "Chunking and preparing review #12...\n",
      "Chunking and preparing review #13...\n",
      "Chunking and preparing review #14...\n",
      "Chunking and preparing review #15...\n",
      "Chunking and preparing review #16...\n",
      "Chunking and preparing review #17...\n",
      "Chunking and preparing review #18...\n",
      "Chunking and preparing review #19...\n",
      "Chunking and preparing review #20...\n",
      "Chunking and preparing review #21...\n",
      "Chunking and preparing review #22...\n",
      "Batch full. Upserting dangerwich batch #1...\n",
      "Finished upserting dangerwich batch #1!!!\n",
      "Chunking and preparing review #23...\n",
      "Chunking and preparing review #24...\n",
      "Chunking and preparing review #25...\n",
      "Chunking and preparing review #26...\n",
      "Chunking and preparing review #27...\n",
      "Chunking and preparing review #28...\n",
      "Chunking and preparing review #29...\n",
      "Chunking and preparing review #30...\n",
      "Chunking and preparing review #31...\n",
      "Chunking and preparing review #32...\n",
      "Chunking and preparing review #33...\n",
      "Chunking and preparing review #34...\n",
      "Chunking and preparing review #35...\n",
      "Chunking and preparing review #36...\n",
      "Chunking and preparing review #37...\n",
      "Chunking and preparing review #38...\n",
      "Chunking and preparing review #39...\n",
      "Chunking and preparing review #40...\n",
      "Chunking and preparing review #41...\n",
      "Chunking and preparing review #42...\n",
      "Chunking and preparing review #43...\n",
      "Chunking and preparing review #44...\n",
      "Chunking and preparing review #45...\n",
      "Chunking and preparing review #46...\n",
      "Chunking and preparing review #47...\n",
      "Chunking and preparing review #48...\n",
      "Chunking and preparing review #49...\n",
      "Chunking and preparing review #50...\n",
      "Chunking and preparing review #51...\n",
      "Batch full. Upserting dangerwich batch #1...\n",
      "Finished upserting dangerwich batch #1!!!\n",
      "Chunking and preparing review #52...\n",
      "Chunking and preparing review #53...\n",
      "Chunking and preparing review #54...\n",
      "Chunking and preparing review #55...\n",
      "Chunking and preparing review #56...\n",
      "Chunking and preparing review #57...\n",
      "Chunking and preparing review #58...\n",
      "Chunking and preparing review #59...\n",
      "Chunking and preparing review #60...\n",
      "Chunking and preparing review #61...\n",
      "Chunking and preparing review #62...\n",
      "Chunking and preparing review #63...\n",
      "Chunking and preparing review #64...\n",
      "Chunking and preparing review #65...\n",
      "Chunking and preparing review #66...\n",
      "Chunking and preparing review #67...\n",
      "Chunking and preparing review #68...\n",
      "Chunking and preparing review #69...\n",
      "Chunking and preparing review #70...\n",
      "Chunking and preparing review #71...\n",
      "Chunking and preparing review #72...\n",
      "Chunking and preparing review #73...\n",
      "Chunking and preparing review #74...\n",
      "Chunking and preparing review #75...\n",
      "Chunking and preparing review #76...\n",
      "Chunking and preparing review #77...\n",
      "Chunking and preparing review #78...\n",
      "Batch full. Upserting dangerwich batch #1...\n",
      "Finished upserting dangerwich batch #1!!!\n",
      "Chunking and preparing review #79...\n",
      "Chunking and preparing review #80...\n",
      "Chunking and preparing review #81...\n",
      "Chunking and preparing review #82...\n",
      "Chunking and preparing review #83...\n",
      "Chunking and preparing review #84...\n",
      "Chunking and preparing review #85...\n",
      "Chunking and preparing review #86...\n",
      "Chunking and preparing review #87...\n",
      "Chunking and preparing review #88...\n",
      "Chunking and preparing review #89...\n",
      "Chunking and preparing review #90...\n",
      "Chunking and preparing review #91...\n",
      "Chunking and preparing review #92...\n",
      "Chunking and preparing review #93...\n",
      "Chunking and preparing review #94...\n",
      "Chunking and preparing review #95...\n",
      "Chunking and preparing review #96...\n",
      "Chunking and preparing review #97...\n",
      "Chunking and preparing review #98...\n",
      "Chunking and preparing review #99...\n",
      "Chunking and preparing review #100...\n",
      "Chunking and preparing review #101...\n",
      "Chunking and preparing review #102...\n",
      "Chunking and preparing review #103...\n",
      "Chunking and preparing review #104...\n",
      "Chunking and preparing review #105...\n",
      "Chunking and preparing review #106...\n",
      "Chunking and preparing review #107...\n",
      "Batch full. Upserting dangerwich batch #1...\n",
      "Finished upserting dangerwich batch #1!!!\n",
      "Chunking and preparing review #108...\n",
      "Chunking and preparing review #109...\n",
      "Chunking and preparing review #110...\n",
      "Chunking and preparing review #111...\n",
      "Chunking and preparing review #112...\n",
      "Chunking and preparing review #113...\n",
      "Chunking and preparing review #114...\n",
      "Chunking and preparing review #115...\n",
      "Chunking and preparing review #116...\n",
      "Chunking and preparing review #117...\n",
      "Chunking and preparing review #118...\n",
      "Chunking and preparing review #119...\n",
      "Chunking and preparing review #120...\n",
      "Chunking and preparing review #121...\n",
      "Chunking and preparing review #122...\n",
      "Chunking and preparing review #123...\n",
      "Chunking and preparing review #124...\n",
      "Chunking and preparing review #125...\n",
      "Chunking and preparing review #126...\n",
      "Chunking and preparing review #127...\n",
      "Chunking and preparing review #128...\n",
      "Chunking and preparing review #129...\n",
      "Chunking and preparing review #130...\n",
      "Chunking and preparing review #131...\n",
      "Chunking and preparing review #132...\n",
      "Chunking and preparing review #133...\n",
      "Chunking and preparing review #134...\n",
      "Batch full. Upserting dangerwich batch #1...\n",
      "Finished upserting dangerwich batch #1!!!\n",
      "Chunking and preparing review #135...\n",
      "Chunking and preparing review #136...\n",
      "Chunking and preparing review #137...\n",
      "Chunking and preparing review #138...\n",
      "Chunking and preparing review #139...\n",
      "Chunking and preparing review #140...\n",
      "Chunking and preparing review #141...\n",
      "Chunking and preparing review #142...\n",
      "Chunking and preparing review #143...\n",
      "Chunking and preparing review #144...\n",
      "Chunking and preparing review #145...\n",
      "Chunking and preparing review #146...\n",
      "Chunking and preparing review #147...\n",
      "Chunking and preparing review #148...\n",
      "Chunking and preparing review #149...\n",
      "Chunking and preparing review #150...\n",
      "Chunking and preparing review #151...\n",
      "Chunking and preparing review #152...\n",
      "Chunking and preparing review #153...\n",
      "Chunking and preparing review #154...\n",
      "Chunking and preparing review #155...\n",
      "Chunking and preparing review #156...\n",
      "Chunking and preparing review #157...\n",
      "Chunking and preparing review #158...\n",
      "Chunking and preparing review #159...\n",
      "Chunking and preparing review #160...\n",
      "Chunking and preparing review #161...\n",
      "Chunking and preparing review #162...\n",
      "Chunking and preparing review #163...\n",
      "Chunking and preparing review #164...\n",
      "Batch full. Upserting dangerwich batch #1...\n",
      "Finished upserting dangerwich batch #1!!!\n",
      "Chunking and preparing review #165...\n",
      "Chunking and preparing review #166...\n",
      "Chunking and preparing review #167...\n",
      "Chunking and preparing review #168...\n",
      "Chunking and preparing review #169...\n",
      "Chunking and preparing review #170...\n",
      "Chunking and preparing review #171...\n",
      "Chunking and preparing review #172...\n",
      "Chunking and preparing review #173...\n",
      "Chunking and preparing review #174...\n",
      "Chunking and preparing review #175...\n",
      "Chunking and preparing review #176...\n",
      "Chunking and preparing review #177...\n",
      "Chunking and preparing review #178...\n",
      "Chunking and preparing review #179...\n",
      "Chunking and preparing review #180...\n",
      "Chunking and preparing review #181...\n",
      "Chunking and preparing review #182...\n",
      "Chunking and preparing review #183...\n",
      "Chunking and preparing review #184...\n",
      "Chunking and preparing review #185...\n",
      "Chunking and preparing review #186...\n",
      "Chunking and preparing review #187...\n",
      "Chunking and preparing review #188...\n",
      "Chunking and preparing review #189...\n",
      "Chunking and preparing review #190...\n",
      "Chunking and preparing review #191...\n",
      "Chunking and preparing review #192...\n",
      "Chunking and preparing review #193...\n",
      "Batch full. Upserting dangerwich batch #1...\n",
      "Finished upserting dangerwich batch #1!!!\n",
      "Chunking and preparing review #194...\n",
      "Chunking and preparing review #195...\n",
      "Chunking and preparing review #196...\n",
      "Chunking and preparing review #197...\n",
      "Chunking and preparing review #198...\n",
      "Chunking and preparing review #199...\n",
      "Chunking and preparing review #200...\n",
      "Chunking and preparing review #201...\n",
      "Chunking and preparing review #202...\n",
      "Chunking and preparing review #203...\n",
      "Chunking and preparing review #204...\n",
      "Chunking and preparing review #205...\n",
      "Chunking and preparing review #206...\n",
      "Chunking and preparing review #207...\n",
      "Chunking and preparing review #208...\n",
      "Chunking and preparing review #209...\n",
      "Chunking and preparing review #210...\n",
      "Chunking and preparing review #211...\n",
      "Chunking and preparing review #212...\n",
      "Chunking and preparing review #213...\n",
      "Chunking and preparing review #214...\n",
      "Chunking and preparing review #215...\n",
      "Chunking and preparing review #216...\n",
      "Chunking and preparing review #217...\n",
      "Chunking and preparing review #218...\n",
      "Chunking and preparing review #219...\n",
      "Chunking and preparing review #220...\n",
      "Chunking and preparing review #221...\n",
      "Chunking and preparing review #222...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch full. Upserting dangerwich batch #1...\n",
      "Finished upserting dangerwich batch #1!!!\n",
      "Chunking and preparing review #223...\n",
      "Chunking and preparing review #224...\n",
      "Chunking and preparing review #225...\n",
      "Chunking and preparing review #226...\n",
      "Chunking and preparing review #227...\n",
      "Chunking and preparing review #228...\n",
      "Chunking and preparing review #229...\n",
      "Chunking and preparing review #230...\n",
      "Chunking and preparing review #231...\n",
      "Chunking and preparing review #232...\n",
      "Chunking and preparing review #233...\n",
      "Chunking and preparing review #234...\n",
      "Chunking and preparing review #235...\n",
      "Chunking and preparing review #236...\n",
      "Chunking and preparing review #237...\n",
      "Chunking and preparing review #238...\n",
      "Chunking and preparing review #239...\n",
      "Chunking and preparing review #240...\n",
      "Chunking and preparing review #241...\n",
      "Chunking and preparing review #242...\n",
      "Chunking and preparing review #243...\n",
      "Chunking and preparing review #244...\n",
      "Chunking and preparing review #245...\n",
      "Chunking and preparing review #246...\n",
      "Chunking and preparing review #247...\n",
      "Chunking and preparing review #248...\n",
      "Chunking and preparing review #249...\n",
      "Chunking and preparing review #250...\n",
      "Chunking and preparing review #251...\n",
      "Chunking and preparing review #252...\n",
      "Batch full. Upserting dangerwich batch #1...\n",
      "Finished upserting dangerwich batch #1!!!\n",
      "Chunking and preparing review #253...\n",
      "Chunking and preparing review #254...\n",
      "Upserting left over dangerwiches...\n",
      "Finished upserting all dangerwiches... BRONCOS COUNTRY. LET'S RIDE!!!\n",
      "End time: 2023-12-08 20:33:18.514635\n",
      "Total elapsed time: 0:27:40.204702\n"
     ]
    }
   ],
   "source": [
    "with open('infatuation_reviews_v3.pkl', 'rb') as file:\n",
    "    resto_reviews = pickle.load(file)\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=2500,\n",
    "                                 chunk_overlap=800,\n",
    "                                 length_function=len)\n",
    "\n",
    "batch_limit = 30\n",
    "batch_count = 1\n",
    "\n",
    "upsert_chunks = []\n",
    "upsert_metadatas = []\n",
    "\n",
    "total_word_cnt = 0\n",
    "\n",
    "start_time = datetime.now()\n",
    "print(f\"Start time: {start_time}\")\n",
    "for i, resto in enumerate(tqdm(resto_reviews)):\n",
    "    print(f\"Chunking and preparing review #{i}...\")\n",
    "    # Clean up review data\n",
    "    cleaned_review = resto['review'].replace('&apos;', \"'\").replace(\"&amp;\", \"&\").replace('&quot;', '\"').replace(\"&quot\", '\"')\n",
    "    cleaned_resto_name = resto['resto_name'].replace(\"&amp;\", \"&\").replace('&apos;', \"'\")\n",
    "    cleaned_resto_tags = resto['perfect_for_tags'].replace(\"&amp;\", \"&\").replace('&apos;', \"'\")\n",
    "    review_date = resto['review_date'].split('T')[0]\n",
    "    \n",
    "    # Set the metadata for this restaurant review\n",
    "    metadata = {\n",
    "        'resto_name': cleaned_resto_name,\n",
    "        'cuisine': resto['cuisine'],\n",
    "        'perfect_for_tags': cleaned_resto_tags,\n",
    "        'price_range': resto['price_range'],\n",
    "        'review_date': review_date,\n",
    "        'image_url': resto['resto_image'],\n",
    "    }\n",
    "    # Split review into chunks\n",
    "    review_chunks = text_splitter.split_text(cleaned_review)\n",
    "    review_chunks = [f\"Perfect for: {cleaned_resto_tags}. Serves {resto['cuisine']}. \" + j for j in review_chunks]\n",
    "    # Create metadata dicts for each chunk\n",
    "    chunk_metadatas = [{\n",
    "        \"chunk\": j, \"text\": text, **metadata\n",
    "    } for j, text in enumerate(review_chunks)]\n",
    "    # Append chunks to list of chunks (to be upserted to Pinecone)\n",
    "    upsert_chunks.extend(review_chunks)\n",
    "    # Append chunks metadatas to list of metadatas (also to be upserted to Pinecone)\n",
    "    upsert_metadatas.extend(chunk_metadatas)\n",
    "    # If we're at the batch_limit, store chunks in Pinecone\n",
    "    if len(upsert_chunks) >= batch_limit:\n",
    "        ids = [str(uuid4()) for _ in range(len(upsert_chunks))]\n",
    "        embeddings = embeddings_model.embed_documents(upsert_chunks)\n",
    "        print(f\"Batch full. Upserting dangerwich batch #{batch_count}...\")\n",
    "        index.upsert(vectors=zip(ids, embeddings, upsert_metadatas))\n",
    "        print(f\"Finished upserting dangerwich batch #{batch_count}!!!\")\n",
    "        upsert_chunks = []\n",
    "        upsert_metadatas = []\n",
    "\n",
    "print(\"Upserting left over dangerwiches...\")\n",
    "ids = [str(uuid4()) for _ in range(len(upsert_chunks))]\n",
    "embeddings = embeddings_model.embed_documents(upsert_chunks)\n",
    "index.upsert(vectors=zip(ids, embeddings, upsert_metadatas))\n",
    "print(\"Finished upserting all dangerwiches... BRONCOS COUNTRY. LET'S RIDE!!!\")\n",
    "\n",
    "end_time = datetime.now()\n",
    "print(f\"End time: {end_time}\")\n",
    "print(f\"Total elapsed time: {end_time - start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8944808c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = Pinecone.from_existing_index(index_name, embeddings_model)\n",
    "query = \"Getting dinner with a group of friends on a Saturday night and want a restaurant with good music and vibes near the East Village\"\n",
    "# Restos are returned as Langchain Documents, containing appropriate metadata and reviews\n",
    "top_restos = vector_store.similarity_search(query, k=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "86905c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Restaurant: Dora's Restaurant\n",
      "Review: Perfect for: Big Groups, Walk-Ins, Peruvian. Serves Peruvian. The dinner you have before you go out is very important. It sets the tone for the rest of the evening, and if you go somewhere boring, you may end up falling asleep standing up later on the dance floor. So, the next time you’re looking for a relatively affordable pre-going out dinner in the East Village, go to Dora’s, a Peruvian spot where the sangria comes in at least six different flavors, and the music plays at a club-level volume. The large, casual space has plastic chairs, a full bar, and a Good Vibes sign that is only sometimes turned on. Order a bunch of ceviches to share, a few rounds of sangria, and maybe even a paella. And if your night begins and ends here, we think that’d be just fine with Dora.\n",
      "Perfect for: Big Groups, Walk-Ins, Peruvian\n",
      "Price Range: $\n",
      "\n",
      "\n",
      "Restaurant: Ella Funt\n",
      "Review: Perfect for: Date Night, French. Serves French. Half the city’s restaurants are currently in an arms race to see who can have the plainest white walls, but not Ella Funt. This East Village spot has a neon-lit kitchen, a gallery-worthy art collection, and a gilded bathroom that’ll make you feel immeasurably wealthy for two to three minutes, depending on how hydrated you are. Named for a drag artist who performed at the club that once occupied the basement (which the owners plan to revive), the place feels slick and offbeat in a way that fits the neighborhood. But, cool as it is, we wouldn’t recommend a full dinner here. If you want to check out this restaurant equivalent of Prada shades paired with Dr. Martens, sit at the bar, drink a glass of skin contact wine, and stick to just one or two French and Asian-inspired small plates. Ella Funt’s neobistro menu starts out strong, and fizzles toward the end. The crunchy little pork croquettes with comte are fantastic, and the tartine with uni and burrata is a certified cheat code. But it’s hard to get amped about a pricey strip steak drowning in a heavy tarragon sauce, or a single ricotta raviolo that tastes like a brief, unsatisfying recap of a story you’ve heard a few times before. To make the most of this place, treat it like a buzzy wine bar or gallery opening, and bring someone who has a rough idea of what they’d wear to the next Raf Simons show. The two of you can explore the natural wine list while you take in the ambiance, which is ultimately more compelling than the food.\n",
      "Perfect for: Date Night, French\n",
      "Price Range: $$$\n",
      "\n",
      "\n",
      "Restaurant: Two Doors Down\n",
      "Review: Perfect for: First/Early in the Game Dates, Bar. Serves Bar. Sometimes, you drink a nice cocktail at a nice bar, and then go somewhere else to lose your dignity. But why bother moving from one place to another, when you could stay where you are, and just head downstairs? At Two Doors Down, a Lower East Side bar from the Cafe Balearica team (another two-floor destination), you can do just that. Upstairs, there’s moody lighting and big booths, and it’s a pleasantly quiet spot for a midweek first date, where you can fill any silences with old Kendrick and sips of a well-made cocktail. But on the weekends the downstairs comes into play. This is where you can listen to a DJ, dance under a disco ball, and forget all about the mediocre date you had upstairs the last time you were here.\n",
      "Perfect for: First/Early in the Game Dates, Bar\n",
      "Price Range: $$\n",
      "\n",
      "\n",
      "Restaurant: Metropolis\n",
      "Review: Perfect for: Big Groups, American. Serves American. Did you know there’s a new performing arts center near the World Trade Center? It cost a little over half a billion dollars, and if you head up the staircase at the entrance, you’ll find an upscale restaurant from Marcus Samuelsson, serving smoked hamachi tacos and grilled short rib that looks and tastes like a fancy McRib. The food is allegedly inspired by the neighborhoods of New York City—similar to Tatiana—although that seems like a stretch at times. Maybe the skimpy $40 crudités platter will remind you of Kips Bay, or maybe it’ll just remind you of a farmer’s market around 5pm, when everything is sold out. The space looks great, like a futuristic living room, and there are some solid bites on the menu, but the overall experience is hit-or-miss.\n",
      "Perfect for: Big Groups, American\n",
      "Price Range: $$$\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for resto in top_restos:\n",
    "    resto_name = resto.metadata['resto_name']\n",
    "    price_range = resto.metadata['price_range']\n",
    "    perfect_for = resto.metadata['perfect_for_tags']\n",
    "    review = resto.page_content\n",
    "    print(f\"\\nRestaurant: {resto_name}\\nReview: {review}\\nPerfect for: {perfect_for}\\nPrice Range: {price_range}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0e5e34c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_str = '&quot;right&quot'\n",
    "cleaned_review = test_str.replace('&quot;', '\"').replace(\"&quot\", '\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d33e854d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"right\"\n"
     ]
    }
   ],
   "source": [
    "print(cleaned_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71a8fe4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53214f20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb17f412",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08e56bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bece45d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "foodApp",
   "language": "python",
   "name": "foodapp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
